{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "636ef974-2e7a-4912-a4bf-657171c343f3",
   "metadata": {},
   "source": [
    "# Model Saturation Testing\n",
    "\n",
    "Train BraTS and COVIDx models with successively fewer data points to test for model saturation for PocketNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a11c37-320f-40a2-86d5-feec5fb33808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "##### Tensorflow #####\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, metrics\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "import tensorflow.keras.backend as K\n",
    "import os\n",
    "\n",
    "# Set this environment variable to allow ModelCheckpoint to work\n",
    "os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'\n",
    "\n",
    "# Set this environment variable to only use the first available GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# For tensorflow 2.x.x allow memory growth on GPU\n",
    "###################################\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "###################################\n",
    "\n",
    "# Use this to allow memory growth on TensorFlow v1.x.x\n",
    "# ###################################\n",
    "# config = tf.ConfigProto()\n",
    " \n",
    "# # Don't pre-allocate memory; allocate as-needed\n",
    "# config.gpu_options.allow_growth = True\n",
    " \n",
    "# # Only allow a specified percent of the GPU memory to be allocated\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.75\n",
    " \n",
    "# # Create a session with the above options specified.\n",
    "# K.tensorflow_backend.set_session(tf.Session(config = config))\n",
    "# ##################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cfcb61-3fdd-4269-808c-d66c7ac22d8c",
   "metadata": {},
   "source": [
    "### L2 Dice Loss\n",
    "\n",
    "Dice loss for BraTS models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835657a1-530a-4e25-8229-5fb66abfdb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 Dice loss\n",
    "def dice_loss_l2(y_true, y_pred):\n",
    "    smooth = 0.0000001\n",
    "    \n",
    "    # (batch size, depth, height, width, channels)\n",
    "    if len(y_true.shape) == 5:\n",
    "        num = K.sum(K.square(y_true - y_pred), axis = (1,2,3))\n",
    "        den = K.sum(K.square(y_true), axis = (1,2,3)) + K.sum(K.square(y_pred), axis = (1,2,3)) + smooth\n",
    "        \n",
    "    # (batch size, height, width, channels)\n",
    "    elif len(y_true.shape) == 4:\n",
    "        num = K.sum(K.square(y_true - y_pred), axis = (1,2))\n",
    "        den = K.sum(K.square(y_true), axis = (1,2)) + K.sum(K.square(y_pred), axis = (1,2)) + smooth\n",
    "        \n",
    "    return K.mean(num/den, axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b154ab-6033-4439-be10-9f054efee211",
   "metadata": {},
   "source": [
    "### Architecture Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831d476f-89bf-470e-9361-eae6f0c46274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PocketNet(inputShape, \n",
    "              numClasses, \n",
    "              mode, \n",
    "              net, \n",
    "              pocket, \n",
    "              initFilters, \n",
    "              depth):\n",
    "    \n",
    "    '''\n",
    "    PocketNet - Smaller CNN for medical image segmentation\n",
    "    \n",
    "    Inputs:\n",
    "    inputShape   : Size of network input - (depth, height, width, channels) for 3D\n",
    "                   (height, width, channels) for 2D\n",
    "    numClasses   : Number of output classes\n",
    "    mode         : 'seg' or 'class' for segmenation or classification network\n",
    "    net          : 'unet', 'resnet', or 'densenet' for U-Net, ResNet or DenseNet blocks\n",
    "    pocket       : True/False for pocket architectures\n",
    "    initFilters  : Number of starting filters at input level\n",
    "    depth        : Number of max-pooling layers\n",
    "    \n",
    "    Outputs:\n",
    "    model        : Keras model for training/predicting\n",
    "    \n",
    "    Author: Adrian Celaya\n",
    "    Last modified: 4.20.2021\n",
    "    '''\n",
    "    \n",
    "    # 3D inputs are (depth, height, width, channels)\n",
    "    if len(inputShape) == 4:\n",
    "        dim = '3d'\n",
    "    # 2D inputs are (height, width, channels)\n",
    "    elif len(inputShape) == 3:\n",
    "        dim = '2d'\n",
    "    \n",
    "    # Convolution block operator\n",
    "    def Block(x, filters, params, net, dim):\n",
    "        ### DenseNet block ###\n",
    "        if net == 'densenet':\n",
    "            for _ in range(2):\n",
    "                if dim == '3d':\n",
    "                    y = layers.Conv3D(filters, **params[0])(x)\n",
    "                elif dim == '2d':\n",
    "                    y = layers.Conv2D(filters, **params[0])(x)\n",
    "                x = layers.concatenate([x, y])\n",
    "                \n",
    "            if dim == '3d':\n",
    "                x = layers.Conv3D(filters, **params[1])(x)\n",
    "            elif dim == '2d':\n",
    "                x = layers.Conv2D(filters, **params[1])(x)\n",
    "        \n",
    "        ### ResNet block ###\n",
    "        elif net == 'resnet':\n",
    "            if dim == '3d':\n",
    "                y = layers.Conv3D(filters, **params[0])(x)\n",
    "                y = layers.Conv3D(filters, **params[0])(y)\n",
    "            elif dim == '2d':\n",
    "                y = layers.Conv2D(filters, **params[0])(x)\n",
    "                y = layers.Conv2D(filters, **params[0])(y)\n",
    "                \n",
    "            x = layers.concatenate([x, y])\n",
    "            \n",
    "            if dim == '3d':\n",
    "                x = layers.Conv3D(filters, **params[1])(x)\n",
    "            elif dim == '2d':\n",
    "                x = layers.Conv2D(filters, **params[1])(x)\n",
    "        \n",
    "        ### U-Net block ###\n",
    "        elif net == 'unet':\n",
    "            if dim == '3d':\n",
    "                x = layers.Conv3D(filters, **params[0])(x)\n",
    "                x = layers.Conv3D(filters, **params[0])(x)\n",
    "            elif dim == '2d':\n",
    "                x = layers.Conv2D(filters, **params[0])(x)\n",
    "                x = layers.Conv2D(filters, **params[0])(x)\n",
    "                \n",
    "        return x\n",
    "\n",
    "    # Downsampling block - Convolution + maxpooling\n",
    "    def TransitionDown(x, filters, params, net, dim):\n",
    "        skip = Block(x, filters, params, net, dim)\n",
    "        \n",
    "        if dim == '3d':\n",
    "            x = layers.MaxPooling3D(pool_size = (1, 2, 2), strides = (1, 2, 2))(skip)\n",
    "        elif dim == '2d':\n",
    "            x = layers.MaxPooling2D(pool_size = (2, 2), strides = (2, 2))(skip)\n",
    "            \n",
    "        return skip, x\n",
    "\n",
    "    # Upsampling block - Transposed convolution + concatenation + convolution\n",
    "    def TransitionUp(x, skip, filters, params, net, dim):\n",
    "        \n",
    "        if dim == '3d':\n",
    "            x = layers.Conv3DTranspose(filters, **params[2])(x)\n",
    "        elif dim == '2d':\n",
    "            x = layers.Conv2DTranspose(filters, **params[2])(x)\n",
    "            \n",
    "        x = layers.concatenate([x, skip])\n",
    "        x = Block(x, filters, params, net, dim)\n",
    "        return x\n",
    "    \n",
    "    # Parameters for each convolution operation\n",
    "    params = list()\n",
    "    if dim == '3d':\n",
    "        params.append(dict(kernel_size = (3, 3, 3), activation = 'relu', padding = 'same'))\n",
    "        params.append(dict(kernel_size = (1, 1, 1), activation = 'relu', padding = 'same'))\n",
    "        params.append(dict(kernel_size = (1, 2, 2), strides = (1, 2, 2), padding = 'same'))\n",
    "    elif dim == '2d':\n",
    "        params.append(dict(kernel_size = (3, 3), activation = 'relu', padding = 'same'))\n",
    "        params.append(dict(kernel_size = (1, 1), activation = 'relu', padding = 'same'))\n",
    "        params.append(dict(kernel_size = (2, 2), strides = (2, 2), padding = 'same'))\n",
    "\n",
    "        \n",
    "    # Keep filters constant for PocketNet\n",
    "    if pocket:\n",
    "        filters = [initFilters for i in range(depth + 1)]\n",
    "    else:\n",
    "        filters = [initFilters * 2 ** (i) for i in range(depth + 1)]\n",
    "    \n",
    "    # Input to network\n",
    "    inputs = layers.Input(inputShape)\n",
    " \n",
    "    # Encoder path\n",
    "    x = inputs\n",
    "    skips = list()\n",
    "    for i in range(depth):\n",
    "        skip, x = TransitionDown(x, filters[i], params, net, dim)\n",
    "        skips.append(skip)\n",
    "        \n",
    "    # Bottleneck\n",
    "    x = Block(x, filters[-1], params, net, dim)\n",
    "\n",
    "    # Apply global max-pooling to output of bottleneck if classification\n",
    "    if mode == 'class':\n",
    "        x = layers.GlobalMaxPooling2D()(x)\n",
    "        output = layers.Dense(numClasses, activation = 'softmax')(x)\n",
    "\n",
    "    \n",
    "    # Continue with decoder path if segmentation\n",
    "    elif mode == 'seg':\n",
    "        \n",
    "        for i in range(depth - 1, -1, -1):\n",
    "            x = TransitionUp(x, skips[i], filters[i], params, net, dim)\n",
    "            \n",
    "        if dim == '3d':\n",
    "            output = layers.Conv3D(numClasses, (1, 1, 1), activation = 'softmax')(x)\n",
    "        elif dim == '2d':\n",
    "            output = layers.Conv2D(numClasses, (1, 1), activation = 'softmax')(x)\n",
    "            \n",
    "    model = Model(inputs = [inputs], outputs = [output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0529bcec-2ab7-472e-887e-5468cb2c2823",
   "metadata": {},
   "source": [
    "### Data Generator \n",
    "\n",
    "Stream data for BraTS models from disk to model while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065c65dd-56dc-4ad1-acec-018e95f358de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_generator(keras.utils.Sequence):\n",
    "    def __init__(self, dataframe, batch_size = 1, dim = (240, 240, 5), n_channels = 4, n_classes = 2, shuffle = True):\n",
    "        self.dim = dim\n",
    "        self.dataframe = dataframe\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.dataframe) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.__data_generation(index)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.dataframe = self.dataframe.sample(frac = 1).reset_index(drop = True)\n",
    "        \n",
    "    def __data_generation(self, index):\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size, *self.dim, self.n_classes))\n",
    "\n",
    "        for i in range(index, index + self.batch_size):\n",
    "            X[i - index] = np.load(self.dataframe.iloc[i]['image'])\n",
    "            y[i - index] = np.load(self.dataframe.iloc[i]['mask'])\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678e41be-2a03-4dbf-add2-75535dace733",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Create predictions on BraTS images after training each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83707dcd-ffaf-4c2e-bfd6-8ec19685ec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_brats(model, df, num_classes, dest):\n",
    "    \n",
    "    dims = sitk.ReadImage(df.iloc[0]['mask'])\n",
    "    dims = sitk.GetArrayFromImage(dims)\n",
    "    dims = dims.shape\n",
    "    \n",
    "    def read_images(image_list, dims):\n",
    "        def get_array(path):\n",
    "            arr = sitk.ReadImage(path)\n",
    "            arr = sitk.Normalize(arr)\n",
    "            arr = sitk.GetArrayFromImage(arr)\n",
    "            return arr\n",
    "\n",
    "        image = np.empty((*dims, len(image_list)))\n",
    "\n",
    "        for i in image_list:\n",
    "            image[..., i] = get_array(i)\n",
    "\n",
    "        return image\n",
    "    \n",
    "    # Define parameters \n",
    "    patients = list(df['id'])\n",
    "    slice_thickness = 5\n",
    "    pred_img_depth = dims[0] + (2 * slice_thickness)\n",
    "    \n",
    "    for i in trange(len(patients)):\n",
    "        \n",
    "        patient = df.iloc[i].to_dict()\n",
    "        \n",
    "        image_list = list(patient.values())[2:len(patient)]\n",
    "        \n",
    "        original = sitk.ReadImage(image_list[0])\n",
    "        \n",
    "        # Load test patient image\n",
    "        image = np.empty((pred_img_depth, dims[1], dims[2], len(image_list)))\n",
    "        image[slice_thickness:(dims[0] - slice_thickness), ...] = read_images(image_list, dims)\n",
    "\n",
    "        # Predict on overlaping tiles of test image\n",
    "        prediction = np.empty((pred_img_depth, dims[1], dims[2], num_classes))\n",
    "        for k in range(pred_img_depth - slice_thickness + 1):\n",
    "            temp = image[k:(k + slice_thickness), ...]\n",
    "            temp = temp.reshape((1, slice_thickness, dims[1], dims[2], len(image_list)))\n",
    "            temp = model.predict(temp)\n",
    "            temp = temp.reshape((slice_thickness, dims[1], dims[2], num_classes))\n",
    "            prediction[k:(k + slice_thickness), ...] += temp\n",
    "\n",
    "        # Take average prediction from overlap strategy and apply argmax to get final array\n",
    "        prediction /= slice_thickness\n",
    "        prediction = prediction[slice_thickness:(pred_img_depth - slice_thickness), ...]\n",
    "        prediction = np.argmax(prediction, axis = -1)\n",
    "        prediction = prediction.reshape((*dims))\n",
    "\n",
    "        # Write prediction as SITK image\n",
    "        pred_sitk = np.zeros((*dims))\n",
    "        for j in range(dims[0]):\n",
    "            pred_sitk[j, ...] = prediction[j, ...]\n",
    "\n",
    "        # Copy header information from t1 image\n",
    "        pred_sitk = sitk.GetImageFromArray(pred_sitk)\n",
    "        pred_sitk.CopyInformation(original)\n",
    "\n",
    "        # Write prediction as nifit file\n",
    "        pred_file = dest + patient['id'] + '_prediction.nii.gz'\n",
    "        sitk.WriteImage(pred_sitk, pred_file)\n",
    "\n",
    "    ##### END OF FUNCTION #####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08dad3d-1c10-4c88-8ade-ecd69651d2fa",
   "metadata": {},
   "source": [
    "Create predictions on COVIDx images after training each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94329844-0fa4-4572-a4c7-2839a7e17d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_covidx(model, df):\n",
    "    preds = list()\n",
    "    for i in trange(len(df)):\n",
    "        img = '/rsrch1/ip/aecelaya/data/covidx/processed/test/' + df.iloc[i]['image']\n",
    "        img = tf.keras.preprocessing.image.load_img(img, color_mode = 'grayscale', target_size = (256, 256))\n",
    "        img = keras.preprocessing.image.img_to_array(img)\n",
    "        \n",
    "        # Apply z-score normalization\n",
    "        mu = np.mean(img)\n",
    "        std = np.std(img)\n",
    "        img = (img - mu) / std\n",
    "        \n",
    "        \n",
    "        img = img.reshape((1, *img.shape))\n",
    "        pred = model.predict(img)\n",
    "        pred = pred[0][-1]\n",
    "        preds.append(pred)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7173d083-2a89-4266-aebd-bd0b8b024ffe",
   "metadata": {},
   "source": [
    "### Run data saturation tests\n",
    "\n",
    "For BraTS and COVIDx, train model with 1.5%, 3%, 5%, 10%, 25%, 50%, and 100% of training data and predict on fixed test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b559f362-8ada-4046-980c-3e61094ee08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_saturation_brats(pocket):\n",
    "    \n",
    "    # Load main dataframe with images and targets\n",
    "    train = pd.read_csv('brats_slices_paths.csv')\n",
    "    pats = np.unique(train['id'])\n",
    "\n",
    "    # Fix a test set and scale up the size of each training set\n",
    "    trainPats, testPats, _, _ = train_test_split(pats, pats, test_size = 0.20, random_state = 0)\n",
    "    trainPats, valPats, _, _ = train_test_split(trainPats, trainPats, test_size = 0.1, random_state = 0)\n",
    "    \n",
    "    original_data = pd.read_csv('brats_paths.csv')\n",
    "    test_original = train.loc[train['id'].isin(testPats)]\n",
    "    test_original = test_original.reset_index(drop = True)\n",
    "    \n",
    "    test = train.loc[train['id'].isin(testPats)]\n",
    "    test = test.reset_index(drop = True)\n",
    "    \n",
    "    val = train.loc[train['id'].isin(valPats)]\n",
    "    val = val.reset_index(drop = True)\n",
    "    numVal = len(val) # Need number of validation patients for keras fit_generator function\n",
    "    \n",
    "    train = train.loc[train['id'].isin(trainPats)]\n",
    "    train = train.reset_index(drop = True)\n",
    "\n",
    "    # Logarithmic data scaling\n",
    "    numTrain = len(trainPats)\n",
    "    logSizes = [0.015, 0.03, 0.05, 0.10, 0.25, 0.50, 1.00]\n",
    "    chunkSize = [int(np.ceil(numTrain * i)) for i in logSizes]\n",
    "    \n",
    "    # For each split, train a model and predict on validation data. Write validation predictions as .nii.gz files.\n",
    "    for i in range(len(logSizes)):\n",
    "        \n",
    "        if pocket:\n",
    "            print('Running pocket ' + net + ' with ' + str(100 * logSizes[i]) + '% of training data')\n",
    "        else:\n",
    "            print('Running full ' + net + ' with ' + str(100 * logSizes[i]) + '% of training data')\n",
    "            \n",
    "        currentPats = trainPats[0:chunkSize[i]]\n",
    "        currentTrain = train.loc[train['id'].isin(currentPats)]\n",
    "        currentTrain = currentTrain.reset_index(drop = True)\n",
    "        numCurrentTrain = len(currentTrain)\n",
    "        \n",
    "        # Create training and validation data generators\n",
    "        batchSize = 4\n",
    "        trainGenerator = data_generator(currentTrain, batchSize)\n",
    "        validationGenerator = data_generator(val, batchSize)\n",
    "\n",
    "        # Create model, compile it, and set up callbacks\n",
    "        model = PocketNet(inputShape = (5, 240, 240, 4), \n",
    "                          numClasses = 2, \n",
    "                          mode = 'seg', \n",
    "                          net = 'unet', \n",
    "                          pocket = pocket, \n",
    "                          initFilters = 16, \n",
    "                          depth = 4)\n",
    "        model.compile(optimizer = 'adam', loss = [dice_loss_l2])\n",
    "\n",
    "        # Reduce learning rate by 0.5 if validation dice coefficient does not improve after 5 epochs\n",
    "        reduceLr = ReduceLROnPlateau(monitor = 'val_loss', \n",
    "                                     mode = 'min',\n",
    "                                     factor = 0.5, \n",
    "                                     patience = 5, \n",
    "                                     min_lr = 0.000001, \n",
    "                                     verbose = 1)\n",
    "\n",
    "        if pocket:\n",
    "            modelName = 'models/' + net + '_pocket_' + str(100 * logSizes[i]) + '.h5'\n",
    "        else:\n",
    "            modelName = 'models/' + net + '_full_' + str(100 * logSizes[i]) + '.h5'\n",
    "        \n",
    "        saveBestModel = ModelCheckpoint(filepath = modelName, \n",
    "                                        monitor = 'val_loss', \n",
    "                                        verbose = 1, \n",
    "                                        save_best_only = True)\n",
    "\n",
    "        # Train model\n",
    "        model.fit(trainGenerator, \n",
    "                  epochs = 50, \n",
    "                  steps_per_epoch = (numCurrentTrain // (batchSize)), \n",
    "                  validation_data = validationGenerator, \n",
    "                  validation_steps = (numVal // (batchSize)), \n",
    "                  callbacks = [reduceLr, saveBestModel], \n",
    "                  verbose = 1,  \n",
    "                  use_multiprocessing = True, \n",
    "                  workers = 8)\n",
    "\n",
    "        \n",
    "        # Use best model to get 3D predictions\n",
    "        model = load_model(modelName, custom_objects = {'dice_loss_l2': dice_loss_l2})\n",
    "        \n",
    "        # Run inference function to write 3D segmentation masks as nifti files\n",
    "        if pocket:\n",
    "            predDest = 'data_scaling/predictions_' + net + '_pocket_' + str(100 * logSizes[i]) + '/'\n",
    "        else:\n",
    "            predDest = 'data_scaling/predictions_' + net + '_full_' + str(100 * logSizes[i]) + '/'\n",
    "            \n",
    "        # Make prediction folder if it does not exist\n",
    "        if not(os.path.isdir(predDest)):\n",
    "            os.mkdir(predDest)\n",
    "        \n",
    "        # Run inference on test set\n",
    "        inference_brats(model, test_original, 2, predDest)\n",
    "\n",
    "    ##### END OF FUNCTION #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093366a6-6768-4cc2-b908-c8b1f0f4bb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_saturation_covidx(pocket):\n",
    "    \n",
    "    # Load main dataframe with images and targets\n",
    "    # Used clean version of COVIDx dataset. See preprocess.ipynb.\n",
    "    train = pd.read_csv('covidx_train_clean.csv')\n",
    "    test = pd.read_csv('test.csv')\n",
    "        \n",
    "    # Convert targets from int to str for Keras generators\n",
    "    train['target'] = train['target'].map(str)\n",
    "    test['target'] = test['target'].map(str)\n",
    "    \n",
    "    # Use COVIDx test set and scale up the size of each training set\n",
    "    train, val, _, _ = train_test_split(train, train['target'], test_size = 0.1, random_state = 0)\n",
    "    train = train.reset_index(drop = True)\n",
    "    val = val.reset_index(drop = True)\n",
    "    val_imbalance = 1 - np.sum(val['target'].map(int)) / len(val)\n",
    "    print('Val class imbalance = ' + str(val_imbalance))\n",
    "    \n",
    "    # Logarithmic data scaling\n",
    "    numTrain = len(train)\n",
    "    logSizes = [0.015, 0.03, 0.05, 0.10, 0.25, 0.50, 1.00]\n",
    "    chunkSize = [int(np.ceil(numTrain * i)) for i in logSizes]\n",
    "    \n",
    "    # Define batchsize for models\n",
    "    batchSize = 32\n",
    "    \n",
    "    # Parameters for Keras generator \n",
    "    flowParams = dict(directory = '/rsrch1/ip/aecelaya/data/covidx/processed/train/', \n",
    "                      x_col = 'image', \n",
    "                      y_col = 'target',\n",
    "                      class_mode = 'categorical', \n",
    "                      color_mode = 'grayscale', \n",
    "                      batch_size = batchSize)\n",
    "    \n",
    "    \n",
    "    # Save predictions here\n",
    "    preds = test[['image', 'target']]\n",
    "        \n",
    "    for i in range(len(logSizes)):\n",
    "        \n",
    "        if pocket:\n",
    "            print('Running pocket ' + net + ' with ' + str(100 * logSizes[i]) + '% of training data')\n",
    "        else:\n",
    "            print('Running full ' + net + ' with ' + str(100 * logSizes[i]) + '% of training data')\n",
    "        \n",
    "        currentTrain = train.iloc[0:chunkSize[i]]\n",
    "\n",
    "        # Create training and validation generators \n",
    "        trainGen = keras.preprocessing.image.ImageDataGenerator(samplewise_center = True, \n",
    "                                                                samplewise_std_normalization = True)\n",
    "        trainGen = trainGen.flow_from_dataframe(currentTrain, **flowParams)\n",
    "        \n",
    "        valGen = keras.preprocessing.image.ImageDataGenerator(samplewise_center = True, \n",
    "                                                              samplewise_std_normalization = True)\n",
    "        valGen = valGen.flow_from_dataframe(val, **flowParams)\n",
    "        \n",
    "        # Create and compile model\n",
    "        model = PocketNet((256, 256, 1), 2, 'class', 'unet', pocket, 16, 4)\n",
    "        model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy', tf.keras.metrics.AUC()])\n",
    "\n",
    "        # Define callbacks\n",
    "        # Reduce learning rate when learning stalls\n",
    "        reduceLr = ReduceLROnPlateau(monitor = 'val_categorical_accuracy', \n",
    "                                     mode = 'max',\n",
    "                                     factor = 0.5, \n",
    "                                     patience = 5, \n",
    "                                     min_lr = 0.000001, \n",
    "                                     verbose = 1)\n",
    "\n",
    "        # Save best model based on validation accuracy\n",
    "        # Name convention: (architecture)_(full/pocket)_(% of training data used).h5 -> unet_pocket_20.h5\n",
    "        if pocket:\n",
    "            modelName = 'models/' + net + '_pocket_' + str(100 * logSizes[i]) + '.h5'\n",
    "        else:\n",
    "            modelName = 'models/' + net + '_full_' + str(100 * logSizes[i]) + '.h5'\n",
    "        \n",
    "        saveBestModel = ModelCheckpoint(filepath = modelName, \n",
    "                                        monitor = 'val_categorical_accuracy', \n",
    "                                        mode = 'max',\n",
    "                                        verbose = 1, \n",
    "                                        save_best_only = True)\n",
    "        \n",
    "        # Fit model\n",
    "        model.fit(trainGen, \n",
    "                  epochs = 50,\n",
    "                  steps_per_epoch = (len(currentTrain)) // batchSize,\n",
    "                  validation_data = valGen,\n",
    "                  validation_steps = (len(val)) // batchSize,\n",
    "                  callbacks = [reduceLr, saveBestModel], \n",
    "                  use_multiprocessing = True, \n",
    "                  workers = 8)\n",
    "        \n",
    "        # Load best model for prediction\n",
    "        model = load_model(modelName)\n",
    "        preds[modelName[7:-3]] = np.array(inference_covidx(model, test))\n",
    "    \n",
    "    # For each network architecture, write scaling results to csv file\n",
    "    if pocket:\n",
    "        csvFile = 'preds_' + net + '_pocket.csv'\n",
    "    else:\n",
    "        csvFile = 'preds_' + net + '_full.csv'\n",
    "   \n",
    "    preds.to_csv(csvFile, index = False)\n",
    "\n",
    "    ### END OF FUNCTION ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fb8b18-b5e6-44ae-bc76-807c59e8b71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pockets = [True, False]\n",
    "for pocket in pockets:\n",
    "    run_saturation_brats(pocket = pockets)\n",
    "    run_saturation_covidx(pocket = pockets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
