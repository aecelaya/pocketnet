{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for BraTS, NFBS, and COVIDx8B datasets\n",
    "\n",
    "#### Change file paths in this notebook to match your system!\n",
    "\n",
    "Preprocessing steps taken:\n",
    "\n",
    "BraTS and NFBS: Load images with SimpleITK -> z-score intensity normalization -> break into patches\n",
    "\n",
    "COVIDx8B: Clean up file names and unzip compressed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CSV with file paths for a dataset\n",
    "def get_paths_csv(base_dir, name_dict, output_csv):\n",
    "    def get_files(path):\n",
    "        files_list = list()\n",
    "        for root, _, files in os.walk(path, topdown = False):\n",
    "            for name in files:\n",
    "                files_list.append(os.path.join(root, name))\n",
    "        return files_list\n",
    "\n",
    "    cols = ['id'] + list(name_dict.keys())\n",
    "    df = pd.DataFrame(columns = cols)\n",
    "    row_dict = dict.fromkeys(cols)\n",
    "\n",
    "    ids = os.listdir(base_dir)\n",
    "\n",
    "    for i in ids:\n",
    "        row_dict['id'] = i\n",
    "        path = os.path.join(base_dir, i)\n",
    "        files = get_files(path)\n",
    "\n",
    "        for file in files:\n",
    "            for img_type in name_dict.keys():\n",
    "                for img_string in name_dict[img_type]:\n",
    "                    if img_string in file:\n",
    "                        row_dict[img_type] = file\n",
    "\n",
    "        df = df.append(row_dict, ignore_index = True)\n",
    "\n",
    "    df.to_csv(output_csv, index = False)\n",
    "    \n",
    "    ################# End of function #################\n",
    "    \n",
    "# Read a nifti file from a given path and return it as a 3D numpy array\n",
    "def ReadImagesSITK(images_list, dims):\n",
    "    \n",
    "    # Read image, normalize, and get numpy array\n",
    "    def GetArray(path):\n",
    "        arr = sitk.ReadImage(path)\n",
    "        arr = sitk.Normalize(arr)\n",
    "        arr = sitk.GetArrayFromImage(arr)\n",
    "        return arr\n",
    "    \n",
    "    image = np.empty((*dims, len(images_list)))\n",
    "    for i in range(len(images_list)):\n",
    "        image[..., i] = GetArray(images_list[i])\n",
    "\n",
    "    return image\n",
    "\n",
    "# Read a segmentation mask from a given path and return one hot representation of mask\n",
    "def ReadMaskSITK(path, classes):\n",
    "    num_classes = len(classes)\n",
    "    mask = sitk.ReadImage(path)\n",
    "    mask = sitk.GetArrayFromImage(mask)\n",
    "    mask_onehot = np.empty((*mask.shape, num_classes))\n",
    "    for i in range(num_classes):\n",
    "        mask_onehot[..., i] = mask == classes[i]\n",
    "    return mask_onehot\n",
    "\n",
    "# Write slices of data from csv\n",
    "def write_slices(input_csv, image_dest, mask_dest, output_csv, image_dims):\n",
    "    input_df = pd.read_csv(input_csv)\n",
    "    num_pats = len(input_df)\n",
    "    slice_thickness = 5\n",
    "    \n",
    "    output_cols = ['id', 'image', 'mask']\n",
    "    output_df = pd.DataFrame(columns = output_cols)\n",
    "    \n",
    "    for i in trange(num_pats):\n",
    "        \n",
    "        # Get row of input dataframe\n",
    "        current_pat = input_df.iloc[i].to_dict()\n",
    "        \n",
    "        # Read in images and masks\n",
    "        images_list = list(current_pat.values())[2:len(current_pat)]\n",
    "        img = ReadImagesSITK(images_list, dims = image_dims)\n",
    "        mask_binary = ReadMaskSITK(current_pat['mask'], classes = [0, 1])\n",
    "        img_depth = image_dims[0]\n",
    "\n",
    "        for k in range(img_depth - slice_thickness + 1):\n",
    "            mask_binary_slice = mask_binary[k:(k + slice_thickness), ...]\n",
    "            \n",
    "            # Only take slices with foreground in them - this is for training only\n",
    "            if  np.sum(mask_binary_slice[..., 1]) > 25:\n",
    "                \n",
    "                # Get corresponding image slices\n",
    "                img_slice = img[k:(k + slice_thickness), ...]\n",
    "                \n",
    "                # Name the slices and write them to disk\n",
    "                slice_name = current_pat['id'] + '_' + str(k) + '.npy'\n",
    "                img_slice_name = image_dest + slice_name\n",
    "                mask_binary_slice_name = mask_dest + slice_name\n",
    "\n",
    "                np.save(img_slice_name, img_slice)\n",
    "                np.save(mask_binary_slice_name, mask_binary_slice)\n",
    "\n",
    "                # Track slices with output dataframe\n",
    "                output_df = output_df.append({'id': current_pat['id'], \n",
    "                                              'image': img_slice_name, \n",
    "                                              'mask': mask_binary_slice_name}, \n",
    "                                              ignore_index = True)\n",
    "    \n",
    "    # Save dataframe to .csv and use the .csv for training the BraTS model\n",
    "    output_df.to_csv(output_csv, index = False)\n",
    "    \n",
    "    ############## END OF FUNCTION ##############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create file path CSVs for BraTS and NFBS datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Create CSV with BraTS file paths #################\n",
    "brats_names_dict = {'mask': ['seg_binary.nii.gz'],\n",
    "                    't1': ['t1.nii.gz'],\n",
    "                    't2': ['t2.nii.gz'], \n",
    "                    'tc': ['t1ce.nii.gz'], \n",
    "                    'fl': ['flair.nii.gz']}\n",
    "\n",
    "# Change this to the appropriate folder on your system \n",
    "brats_base_dir = '/rsrch1/ip/aecelaya/data/brats_2020/raw/train/'\n",
    "\n",
    "brats_output_csv = 'brats_paths.csv'\n",
    "get_paths_csv(brats_base_dir, brats_names_dict, brats_output_csv)\n",
    "\n",
    "################# Create CSV with NFBS file paths #################\n",
    "nfbs_names_dict = {'mask': ['brainmask.nii.gz'],\n",
    "                   't1': ['T1w.nii.gz']}\n",
    "\n",
    "# Change this to the appropriate folder on your system \n",
    "nfbs_base_dir = '/rsrch1/ip/aecelaya/data/nfbs/raw/'\n",
    "\n",
    "nfbs_output_csv = 'nfbs_paths.csv'\n",
    "get_paths_csv(nfbs_base_dir, nfbs_names_dict, nfbs_output_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess BraTS and NFBS and write slices to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Preprocess and write BraTS slices to disk #################\n",
    "brats_input_csv = 'brats_paths.csv'\n",
    "\n",
    "# Change these to the appropriate folder on your system \n",
    "brats_image_dest = '/rsrch1/ip/aecelaya/github/NecrosisRecurrence/pocketnet/brats/test/images/'\n",
    "brats_mask_dest = '/rsrch1/ip/aecelaya/github/NecrosisRecurrence/pocketnet/brats/test/masks/'\n",
    "\n",
    "\n",
    "brats_output_csv = 'brats_slices_paths.csv'\n",
    "\n",
    "write_slices(brats_input_csv, brats_image_dest, brats_mask_dest, brats_output_csv, image_dims = (155, 240, 240))\n",
    "\n",
    "################# Preprocess and write NFBS slices to disk #################\n",
    "nfbs_input_csv = 'nfbs_paths.csv'\n",
    "\n",
    "# Change these to the appropriate folder on your system \n",
    "nfbs_image_dest = '/rsrch1/ip/aecelaya/github/NecrosisRecurrence/pocketnet/brats/test2/images/'\n",
    "nfbs_mask_dest = '/rsrch1/ip/aecelaya/github/NecrosisRecurrence/pocketnet/brats/test2/masks/'\n",
    "\n",
    "nfbs_output_csv = 'nfbs_slices_paths.csv'\n",
    "\n",
    "write_slices(nfbs_input_csv, nfbs_image_dest, nfbs_mask_dest, nfbs_output_csv, image_dims = (192, 256, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up file names for COVIDx8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Clean up the COVIDx dataset. There are a few glitches in it. This script corrects them.\n",
    "\n",
    "1) Some files in the COVIDx training set are compressed (i.e., end with .gz). Keras can't read\n",
    "zipped files with its native image data generators. This script goes through each file\n",
    "and checks to see if its compressed and unzips it if it is. \n",
    "\n",
    "2) The original train.csv file that comes with the COVIDx dataset has incorrect file names for rows\n",
    "725 - 1667. These rows only contian numbers and not the name of an image. For example, row 725 has \n",
    "the entry 1 but it should be COVID1.png.\n",
    "\n",
    "Before running this, please change the file paths in this code to match your system.\n",
    "'''\n",
    "\n",
    "def get_files(dir_name):\n",
    "    list_of_files = list()\n",
    "    for (dirpath, dirnames, filenames) in os.walk(dir_name):\n",
    "        list_of_files += [os.path.join(dirpath, file) for file in filenames]\n",
    "    return list_of_files\n",
    "\n",
    "files_list = get_files('/rsrch1/ip/aecelaya/data/covidx/processed/train')\n",
    "for file in files_list:\n",
    "    if '(' in file:\n",
    "        new_file = file.replace('(', '')\n",
    "        new_file = new_file.replace(')', '')\n",
    "        print('Renaming ' + file + ' to ' + new_file)\n",
    "        os.rename(file, new_file)\n",
    "        file = new_file\n",
    "        \n",
    "    if '.gz' in file:\n",
    "        # Unzip files with gunzip\n",
    "        print('Unzipping ' + file)\n",
    "        subprocess.call('gunzip ' + file, shell = True)\n",
    "        \n",
    "train_df = pd.read_csv('/rsrch1/ip/aecelaya/data/covidx/raw/data/train.csv')\n",
    "for i in range(724, 1667):\n",
    "    number = train_df.iloc[i]['image']\n",
    "    train_df.at[i, 'image'] = 'COVID' + number + '.png'\n",
    "    \n",
    "for i in range(len(train_df)):\n",
    "    file = '/rsrch1/ip/aecelaya/data/covidx/train/' + train_df.iloc[i]['image']\n",
    "    if not os.path.isfile(file):\n",
    "        print('Does not exist: ' + file + ', row = ' + str(i))\n",
    "\n",
    "train_df.to_csv('covidx_train_clean.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
