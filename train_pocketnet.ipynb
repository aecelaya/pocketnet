{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "817393b5-b2e4-41ec-b189-ae6dac20d627",
   "metadata": {},
   "source": [
    "# Run K-Fold for Segmentation Tasks\n",
    "\n",
    "Run a five-fold cross validation for each architecture on NFBS and BraTS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fff14bd-cdad-4551-bbe7-f9f8ddf14d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "##### Tensorflow #####\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, metrics\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "import tensorflow.keras.backend as K\n",
    "import os\n",
    "\n",
    "# Set this environment variable to allow ModelCheckpoint to work\n",
    "os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'\n",
    "\n",
    "# Set this environment variable to only use the first available GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# For tensorflow 2.x.x allow memory growth on GPU\n",
    "###################################\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "###################################\n",
    "\n",
    "# Use this to allow memory growth on TensorFlow v1.x.x\n",
    "# ###################################\n",
    "# config = tf.ConfigProto()\n",
    " \n",
    "# # Don't pre-allocate memory; allocate as-needed\n",
    "# config.gpu_options.allow_growth = True\n",
    " \n",
    "# # Only allow a specified percent of the GPU memory to be allocated\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.75\n",
    " \n",
    "# # Create a session with the above options specified.\n",
    "# K.tensorflow_backend.set_session(tf.Session(config = config))\n",
    "# ##################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580824f6-494c-4d0f-be82-29bec1ddc5a2",
   "metadata": {},
   "source": [
    "### L2 Dice Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cc92a6-62d4-4259-9ff6-b038769d4891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 Dice loss\n",
    "def dice_loss_l2(y_true, y_pred):\n",
    "    smooth = 0.0000001\n",
    "    \n",
    "    # (batch size, depth, height, width, channels)\n",
    "    if len(y_true.shape) == 5:\n",
    "        num = K.sum(K.square(y_true - y_pred), axis = (1,2,3))\n",
    "        den = K.sum(K.square(y_true), axis = (1,2,3)) + K.sum(K.square(y_pred), axis = (1,2,3)) + smooth\n",
    "        \n",
    "    # (batch size, height, width, channels)\n",
    "    elif len(y_true.shape) == 4:\n",
    "        num = K.sum(K.square(y_true - y_pred), axis = (1,2))\n",
    "        den = K.sum(K.square(y_true), axis = (1,2)) + K.sum(K.square(y_pred), axis = (1,2)) + smooth\n",
    "        \n",
    "    return K.mean(num/den, axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9faf7af-47f1-4c43-85e9-683e7b2ffb7e",
   "metadata": {},
   "source": [
    "### Architecture Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769fa021-d28c-41e7-8220-35061743d5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PocketNet(inputShape, \n",
    "              numClasses, \n",
    "              mode, \n",
    "              net, \n",
    "              pocket, \n",
    "              initFilters, \n",
    "              depth):\n",
    "    \n",
    "    '''\n",
    "    PocketNet - Smaller CNN for medical image segmentation\n",
    "    \n",
    "    Inputs:\n",
    "    inputShape   : Size of network input - (depth, height, width, channels) for 3D\n",
    "                   (height, width, channels) for 2D\n",
    "    numClasses   : Number of output classes\n",
    "    mode         : 'seg' or 'class' for segmenation or classification network\n",
    "    net          : 'unet', 'resnet', or 'densenet' for U-Net, ResNet or DenseNet blocks\n",
    "    pocket       : True/False for pocket architectures\n",
    "    initFilters  : Number of starting filters at input level\n",
    "    depth        : Number of max-pooling layers\n",
    "    \n",
    "    Outputs:\n",
    "    model        : Keras model for training/predicting\n",
    "    \n",
    "    Author: Adrian Celaya\n",
    "    Last modified: 4.20.2021\n",
    "    '''\n",
    "    \n",
    "    # 3D inputs are (depth, height, width, channels)\n",
    "    if len(inputShape) == 4:\n",
    "        dim = '3d'\n",
    "    # 2D inputs are (height, width, channels)\n",
    "    elif len(inputShape) == 3:\n",
    "        dim = '2d'\n",
    "    \n",
    "    # Convolution block operator\n",
    "    def Block(x, filters, params, net, dim):\n",
    "        ### DenseNet block ###\n",
    "        if net == 'densenet':\n",
    "            for _ in range(2):\n",
    "                if dim == '3d':\n",
    "                    y = layers.Conv3D(filters, **params[0])(x)\n",
    "                elif dim == '2d':\n",
    "                    y = layers.Conv2D(filters, **params[0])(x)\n",
    "                x = layers.concatenate([x, y])\n",
    "                \n",
    "            if dim == '3d':\n",
    "                x = layers.Conv3D(filters, **params[1])(x)\n",
    "            elif dim == '2d':\n",
    "                x = layers.Conv2D(filters, **params[1])(x)\n",
    "        \n",
    "        ### ResNet block ###\n",
    "        elif net == 'resnet':\n",
    "            if dim == '3d':\n",
    "                y = layers.Conv3D(filters, **params[0])(x)\n",
    "                y = layers.Conv3D(filters, **params[0])(y)\n",
    "            elif dim == '2d':\n",
    "                y = layers.Conv2D(filters, **params[0])(x)\n",
    "                y = layers.Conv2D(filters, **params[0])(y)\n",
    "                \n",
    "            x = layers.concatenate([x, y])\n",
    "            \n",
    "            if dim == '3d':\n",
    "                x = layers.Conv3D(filters, **params[1])(x)\n",
    "            elif dim == '2d':\n",
    "                x = layers.Conv2D(filters, **params[1])(x)\n",
    "        \n",
    "        ### U-Net block ###\n",
    "        elif net == 'unet':\n",
    "            if dim == '3d':\n",
    "                x = layers.Conv3D(filters, **params[0])(x)\n",
    "                x = layers.Conv3D(filters, **params[0])(x)\n",
    "            elif dim == '2d':\n",
    "                x = layers.Conv2D(filters, **params[0])(x)\n",
    "                x = layers.Conv2D(filters, **params[0])(x)\n",
    "                \n",
    "        return x\n",
    "\n",
    "    # Downsampling block - Convolution + maxpooling\n",
    "    def TransitionDown(x, filters, params, net, dim):\n",
    "        skip = Block(x, filters, params, net, dim)\n",
    "        \n",
    "        if dim == '3d':\n",
    "            x = layers.MaxPooling3D(pool_size = (1, 2, 2), strides = (1, 2, 2))(skip)\n",
    "        elif dim == '2d':\n",
    "            x = layers.MaxPooling2D(pool_size = (2, 2), strides = (2, 2))(skip)\n",
    "            \n",
    "        return skip, x\n",
    "\n",
    "    # Upsampling block - Transposed convolution + concatenation + convolution\n",
    "    def TransitionUp(x, skip, filters, params, net, dim):\n",
    "        \n",
    "        if dim == '3d':\n",
    "            x = layers.Conv3DTranspose(filters, **params[2])(x)\n",
    "        elif dim == '2d':\n",
    "            x = layers.Conv2DTranspose(filters, **params[2])(x)\n",
    "            \n",
    "        x = layers.concatenate([x, skip])\n",
    "        x = Block(x, filters, params, net, dim)\n",
    "        return x\n",
    "    \n",
    "    # Parameters for each convolution operation\n",
    "    params = list()\n",
    "    if dim == '3d':\n",
    "        params.append(dict(kernel_size = (3, 3, 3), activation = 'relu', padding = 'same'))\n",
    "        params.append(dict(kernel_size = (1, 1, 1), activation = 'relu', padding = 'same'))\n",
    "        params.append(dict(kernel_size = (1, 2, 2), strides = (1, 2, 2), padding = 'same'))\n",
    "    elif dim == '2d':\n",
    "        params.append(dict(kernel_size = (3, 3), activation = 'relu', padding = 'same'))\n",
    "        params.append(dict(kernel_size = (1, 1), activation = 'relu', padding = 'same'))\n",
    "        params.append(dict(kernel_size = (2, 2), strides = (2, 2), padding = 'same'))\n",
    "\n",
    "        \n",
    "    # Keep filters constant for PocketNet\n",
    "    if pocket:\n",
    "        filters = [initFilters for i in range(depth + 1)]\n",
    "    else:\n",
    "        filters = [initFilters * 2 ** (i) for i in range(depth + 1)]\n",
    "    \n",
    "    # Input to network\n",
    "    inputs = layers.Input(inputShape)\n",
    " \n",
    "    # Encoder path\n",
    "    x = inputs\n",
    "    skips = list()\n",
    "    for i in range(depth):\n",
    "        skip, x = TransitionDown(x, filters[i], params, net, dim)\n",
    "        skips.append(skip)\n",
    "        \n",
    "    # Bottleneck\n",
    "    x = Block(x, filters[-1], params, net, dim)\n",
    "\n",
    "    # Apply global max-pooling to output of bottleneck if classification\n",
    "    if mode == 'class':\n",
    "        x = layers.GlobalMaxPooling2D()(x)\n",
    "        output = layers.Dense(numClasses, activation = 'softmax')(x)\n",
    "\n",
    "    \n",
    "    # Continue with decoder path if segmentation\n",
    "    elif mode == 'seg':\n",
    "        \n",
    "        for i in range(depth - 1, -1, -1):\n",
    "            x = TransitionUp(x, skips[i], filters[i], params, net, dim)\n",
    "            \n",
    "        if dim == '3d':\n",
    "            output = layers.Conv3D(numClasses, (1, 1, 1), activation = 'softmax')(x)\n",
    "        elif dim == '2d':\n",
    "            output = layers.Conv2D(numClasses, (1, 1), activation = 'softmax')(x)\n",
    "            \n",
    "    model = Model(inputs = [inputs], outputs = [output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee28ed40-dcfd-4872-86fa-2deb81c29505",
   "metadata": {},
   "source": [
    "### Data Generator \n",
    "\n",
    "Stream data from disk to model while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e8f945-715e-4d83-b4fa-72affcba469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_generator(keras.utils.Sequence):\n",
    "    def __init__(self, dataframe, batch_size, dim, n_channels, n_classes, shuffle):\n",
    "        self.dim = dim\n",
    "        self.dataframe = dataframe\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.dataframe) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.__data_generation(index)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.dataframe = self.dataframe.sample(frac = 1).reset_index(drop = True)\n",
    "        \n",
    "    def __data_generation(self, index):\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size, *self.dim, self.n_classes))\n",
    "\n",
    "        for i in range(index, index + self.batch_size):\n",
    "            X[i - index] = np.load(self.dataframe.iloc[i]['image'])\n",
    "            y[i - index] = np.load(self.dataframe.iloc[i]['mask'])\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c044c2-831d-4ba4-a8fc-d86e2f5b2980",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Create predictions on images after training each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e7a846-3843-4620-902c-e4954746e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, df, num_classes, dest):\n",
    "    \n",
    "    dims = sitk.ReadImage(df.iloc[0]['mask'])\n",
    "    dims = sitk.GetArrayFromImage(dims)\n",
    "    dims = dims.shape\n",
    "    \n",
    "    def read_images(image_list, dims):\n",
    "        def get_array(path):\n",
    "            arr = sitk.ReadImage(path)\n",
    "            arr = sitk.Normalize(arr)\n",
    "            arr = sitk.GetArrayFromImage(arr)\n",
    "            return arr\n",
    "\n",
    "        image = np.empty((*dims, len(image_list)))\n",
    "\n",
    "        for i in image_list\n",
    "            image[..., i] = get_array(i)\n",
    "\n",
    "        return image\n",
    "    \n",
    "    # Define parameters \n",
    "    patients = list(df['id'])\n",
    "    slice_thickness = 5\n",
    "    pred_img_depth = dims[0] + (2 * slice_thickness)\n",
    "    \n",
    "    for i in trange(len(patients)):\n",
    "        \n",
    "        patient = df.iloc[i].to_dict()\n",
    "        \n",
    "        image_list = list(patient.values())[2:len(patient)]\n",
    "        \n",
    "        original = sitk.ReadImage(image_list[0])\n",
    "        \n",
    "        # Load test patient image\n",
    "        image = np.zeros((pred_img_depth, dims[1], dims[2], len(image_list)))\n",
    "        image[slice_thickness:(dims[0] - slice_thickness), ...] = read_images(image_list, dims)\n",
    "\n",
    "        # Predict on overlaping tiles of test image\n",
    "        prediction = np.zeros((pred_img_depth, dims[1], dims[2], num_classes))\n",
    "        for k in range(pred_img_depth - slice_thickness + 1):\n",
    "            temp = image[k:(k + slice_thickness), ...]\n",
    "            temp = temp.reshape((1, slice_thickness, dims[1], dims[2], len(image_list)))\n",
    "            temp = model.predict(temp)\n",
    "            temp = temp.reshape((slice_thickness, dims[1], dims[2], num_classes))\n",
    "            prediction[k:(k + slice_thickness), ...] += temp\n",
    "\n",
    "        # Take average prediction from overlap strategy and apply argmax to get final array\n",
    "        prediction /= slice_thickness\n",
    "        prediction = prediction[slice_thickness:(pred_img_depth - slice_thickness), ...]\n",
    "        prediction = np.argmax(prediction, axis = -1)\n",
    "        prediction = prediction.reshape((*dims))\n",
    "\n",
    "        # Write prediction as SITK image\n",
    "        pred_sitk = np.zeros((*dims))\n",
    "        for j in range(dims[0]):\n",
    "            pred_sitk[j, ...] = prediction[j, ...]\n",
    "\n",
    "        # Copy header information from t1 image\n",
    "        pred_sitk = sitk.GetImageFromArray(pred_sitk)\n",
    "        pred_sitk.CopyInformation(original)\n",
    "\n",
    "        # Write prediction as nifit file\n",
    "        pred_file = dest + patient['id'] + '_prediction.nii.gz'\n",
    "        sitk.WriteImage(pred_sitk, pred_file)\n",
    "\n",
    "    ##### END OF FUNCTION #####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1511598-3d42-4bf5-a5bc-ad4e855c8501",
   "metadata": {},
   "source": [
    "### K-Folds\n",
    "\n",
    "Create folds and train model on each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9606ce8a-091d-44e1-ab34-01af2fe258ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kfold(input_csv, original_csv, net, pocket, pred_dest, model_dir):\n",
    "    \n",
    "    # Read in csv with paths to images and masks\n",
    "    df = pd.read_csv(input_csv)\n",
    "    df = df.sample(frac = 1).reset_index(drop = True)\n",
    "    \n",
    "    dims_mask = np.load(df.iloc[0]['mask'])\n",
    "    dims_mask = dims_mask.shape\n",
    "    n_classes = dims_mask[-1]\n",
    "    \n",
    "    dims_image = np.load(df.iloc[0]['image'])\n",
    "    dims_image = dims_image.shape\n",
    "    n_channels = dims_image[-1]\n",
    "    \n",
    "    original_data = pd.read_csv(original_csv)\n",
    "    \n",
    "    # Get unique patient IDs and split them into training and validation with Kfold split\n",
    "    patients = np.unique(df['id'])\n",
    "    kfold = KFold(n_splits = 5)\n",
    "    splits = kFolds.split(patients)\n",
    "    \n",
    "    # For each split, train a model and predict on validation data. Write validation predictions as .nii.gz files.\n",
    "    split_id = 1\n",
    "    for split in splits:\n",
    "\n",
    "        train_pats = list(patients[split[0]])\n",
    "        val_pats = list(patients[split[1]])\n",
    "\n",
    "        print('Starting split ' + str(split_id) + ' of ' + str(5))\n",
    "        # Create DataFrames with only training and validation patients for this split\n",
    "        train_df = df[df['id'].isin(train_pats)]\n",
    "        val_df = df[df['id'].isin(val_pats)]\n",
    "        val_images = original_data[original_data['id'].isin(val_pats)]\n",
    "        \n",
    "        num_train = len(train_df)\n",
    "        num_val = len(val_df)\n",
    "\n",
    "        # Create training and validation data generators\n",
    "        batch_size = 4\n",
    "        train_gen = data_generator(train_df, batch_size, dims_image[0:-1], n_channels, n_classes, True)\n",
    "        val_gen = data_generator(val_df, batch_size, dims_image[0:-1], n_channels, n_classes, True)\n",
    "\n",
    "        # Create model, compile it, and set up callbacks\n",
    "        model = PocketNet(inputShape = dims_image, \n",
    "                          numClasses = n_classes, \n",
    "                          mode = 'seg', \n",
    "                          net = net, \n",
    "                          pocket = pocket, \n",
    "                          initFilters = 16, \n",
    "                          depth = 4)\n",
    "        model.compile(optimizer = 'adam', loss = [dice_loss_l2])\n",
    "\n",
    "        # Reduce learning rate by 0.5 if validation dice coefficient does not improve after 5 epochs\n",
    "        reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', \n",
    "                                      mode = 'min',\n",
    "                                      factor = 0.5, \n",
    "                                      patience = 5, \n",
    "                                      min_lr = 0.000001, \n",
    "                                      verbose = 1)\n",
    "\n",
    "        if pocket:\n",
    "            model_name = model_dir + 'pocket_' + net + '_split_' + str(split_id) + '.h5'\n",
    "        else:\n",
    "            model_name = model_dir + 'full_' + net + '_split_' + str(split_id) + '.h5'\n",
    "            \n",
    "        best_model = ModelCheckpoint(filepath = model_name, \n",
    "                                     monitor = 'val_loss', \n",
    "                                     verbose = 1, \n",
    "                                     save_best_only = True)\n",
    "\n",
    "        # Train model\n",
    "        model.fit_generator(train_gen, \n",
    "                            epochs = 50, \n",
    "                            steps_per_epoch = (num_train // (4 * batch_size)), \n",
    "                            validation_data = val_gen, \n",
    "                            validation_steps = (num_val // (4 * batch_size)), \n",
    "                            callbacks = [reduce_lr, best_model], \n",
    "                            verbose = 1)\n",
    "\n",
    "        # Use model to get 3D predictions\n",
    "        model = load_model(model_name, custom_objects = {'dice_loss_l2': dice_loss_l2})\n",
    "        inference(model, val_images, pred_dest)\n",
    "        \n",
    "        split_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e968900-439d-4360-ab30-34728d03b552",
   "metadata": {},
   "source": [
    "Run K-fold code on the BraTS and NFBS datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d28681-36bc-40c0-91ec-4ec2e306466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = ['unet', 'resnet', 'densenet']\n",
    "pockets = [True, False]\n",
    "\n",
    "for net in nets:\n",
    "    for pocket in pockets:\n",
    "        run_kfold('brats_slices_paths.csv', 'brats_paths.csv', net, pocket, '/path/to/brats/predictions/', '/path/to/brats/models/')\n",
    "        run_kfold('nfbs_slices_paths.csv', 'nfbs_paths.csv', net, pocket, '/path/to/nfbs/predictions/', '/path/to/nfbs/models/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
